{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2c0e74",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Este documento presenta un sistema de preparación de datos para implementar Retrieval-Augmented Generation (RAG). El sistema transforma datos en formato CSV a múltiples formatos optimizados para diferentes estrategias de embeddings y búsqueda semántica.\n",
    "\n",
    "### 1.1 Concepto de RAG\n",
    "\n",
    "RAG es una técnica que combina dos componentes:\n",
    "\n",
    "**Retrieval (Recuperación):**\n",
    "- Búsqueda de documentos relevantes en una base de conocimiento\n",
    "- Utiliza similitud semántica mediante embeddings\n",
    "- Encuentra contexto específico del dominio\n",
    "\n",
    "**Generation (Generación):**\n",
    "- Modelo de lenguaje genera respuestas\n",
    "- Utiliza documentos recuperados como contexto\n",
    "- Reduce alucinaciones y mejora precisión\n",
    "\n",
    "### 1.2 Ventajas del RAG\n",
    "\n",
    "**Sobre Fine-Tuning:**\n",
    "- No requiere reentrenamiento del modelo\n",
    "- Actualización instantánea de conocimiento\n",
    "- Menor costo computacional\n",
    "- Trazabilidad de fuentes\n",
    "\n",
    "**Sobre Prompts Simples:**\n",
    "- Acceso a conocimiento específico no presente en el modelo\n",
    "- Respuestas fundamentadas en documentos reales\n",
    "- Manejo de dominios especializados\n",
    "- Escalabilidad con grandes corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0eb0b7",
   "metadata": {},
   "source": [
    "## 2. Dataset Base\n",
    "\n",
    "### 2.1 Estructura del Dataset\n",
    "\n",
    "El sistema trabaja con un dataset CSV que contiene publicaciones de redes sociales:\n",
    "\n",
    "| Campo | Tipo | Descripción |\n",
    "|-------|------|-------------|\n",
    "| `id` | int | Identificador único del documento |\n",
    "| `fecha` | date | Fecha de publicación |\n",
    "| `usuario` | string | ID del usuario autor |\n",
    "| `texto` | string | Contenido textual del documento |\n",
    "| `tema` | string | Categoría temática |\n",
    "| `sentimiento` | string | Análisis de sentimiento (positivo/neutral/negativo) |\n",
    "| `likes` | int | Número de interacciones positivas |\n",
    "| `reposts` | int | Número de compartidos |\n",
    "\n",
    "### 2.2 Temáticas del Corpus\n",
    "\n",
    "El dataset abarca tres temas principales:\n",
    "\n",
    "**Generación Z y Crisis de Sentido:**\n",
    "- Búsqueda de propósito en la era digital\n",
    "- Presión por productividad constante\n",
    "- Vacío existencial en hiperconectividad\n",
    "- Expectativas vs. realidad\n",
    "\n",
    "**Cultura de lo Efímero y Proyectos de Vida:**\n",
    "- Inmediatez vs. compromisos duraderos\n",
    "- Identidad fluida y cambios acelerados\n",
    "- Recompensas instantáneas vs. paciencia\n",
    "- Construcción de proyectos a largo plazo\n",
    "\n",
    "**IA y Pérdida de Autonomía Humana:**\n",
    "- Algoritmos y libertad de elección\n",
    "- Delegación de decisiones a la tecnología\n",
    "- Predicción de comportamiento\n",
    "- Balance entre asistencia y dependencia\n",
    "\n",
    "### 2.3 Estadísticas del Dataset\n",
    "\n",
    "**Volumen:**\n",
    "- Dataset original: 381 documentos\n",
    "- Dataset ampliado: 5,000 documentos\n",
    "\n",
    "**Engagement:**\n",
    "- Promedio de likes por documento\n",
    "- Promedio de reposts por documento\n",
    "- Métrica combinada de engagement\n",
    "\n",
    "**Distribución:**\n",
    "- Balance entre temas\n",
    "- Distribución de sentimientos\n",
    "- Longitud promedio de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563c153",
   "metadata": {},
   "source": [
    "## 3. Formatos de Salida\n",
    "\n",
    "El sistema genera cuatro formatos diferentes, cada uno optimizado para un caso de uso específico:\n",
    "\n",
    "### 3.1 Corpus Simple (corpus_simple.json)\n",
    "\n",
    "**Estructura:**\n",
    "```json\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"texto\": \"Contenido limpio sin enriquecimiento\",\n",
    "  \"metadata\": {\n",
    "    \"fecha\": \"2022-05-01\",\n",
    "    \"tema\": \"Categoría\",\n",
    "    \"sentimiento\": \"neutral\",\n",
    "    \"likes\": 1056,\n",
    "    \"repostos\": 2652\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Características:**\n",
    "- Texto original sin modificaciones\n",
    "- Metadata separada del contenido\n",
    "- Óptimo para embeddings puros\n",
    "\n",
    "**Casos de Uso:**\n",
    "- Modelos de embeddings que separan texto y metadata\n",
    "- Búsqueda basada únicamente en contenido semántico\n",
    "- Análisis de similitud sin sesgos de categorización\n",
    "\n",
    "### 3.2 Corpus Enriquecido (corpus_enriquecido.json)\n",
    "\n",
    "**Estructura:**\n",
    "```json\n",
    "{\n",
    "  \"id\": 1,\n",
    "  \"texto\": \"[Tema] [Sentimiento] Contenido original\",\n",
    "  \"texto_original\": \"Contenido sin modificar\",\n",
    "  \"metadata\": {...}\n",
    "}\n",
    "```\n",
    "\n",
    "**Características:**\n",
    "- Prefijos con tema y sentimiento\n",
    "- Preserva texto original\n",
    "- Enriquecimiento contextual en el embedding\n",
    "\n",
    "**Casos de Uso:**\n",
    "- Búsqueda que considera categorías\n",
    "- Filtrado implícito por tema o sentimiento\n",
    "- Mejora de precisión con contexto adicional\n",
    "\n",
    "### 3.3 Textos Planos (textos_planos.txt)\n",
    "\n",
    "**Estructura:**\n",
    "```\n",
    "Texto del documento 1\n",
    "Texto del documento 2\n",
    "Texto del documento 3\n",
    "...\n",
    "```\n",
    "\n",
    "**Características:**\n",
    "- Un documento por línea\n",
    "- Sin metadatos ni estructura JSON\n",
    "- Formato minimalista\n",
    "\n",
    "**Casos de Uso:**\n",
    "- Modelos que requieren entrada en texto plano\n",
    "- Procesamiento batch simple\n",
    "- Herramientas de línea de comandos\n",
    "\n",
    "### 3.4 Corpus RAG (corpus_rag.json)\n",
    "\n",
    "**Estructura:**\n",
    "```json\n",
    "{\n",
    "  \"id\": \"doc_1\",\n",
    "  \"content\": \"Texto limpio\",\n",
    "  \"enriched_content\": \"Tema: X\\nSentimiento: Y\\n\\nTexto\",\n",
    "  \"metadata\": {\n",
    "    \"engagement\": 3708,\n",
    "    ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Características:**\n",
    "- Dos versiones del contenido\n",
    "- ID con prefijo descriptivo\n",
    "- Métrica de engagement combinada\n",
    "- Formato estructurado para RAG\n",
    "\n",
    "**Casos de Uso:**\n",
    "- Sistemas RAG completos\n",
    "- Permite elegir entre contenido simple o enriquecido\n",
    "- Ordenamiento por relevancia (engagement)\n",
    "- Visualización de fuentes al usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed8b7c",
   "metadata": {},
   "source": [
    "## 4. Pipeline de Transformación\n",
    "\n",
    "### 4.1 Flujo General\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────┐\n",
    "│     Dataset CSV Original                │\n",
    "│  (5000 documentos con metadata)         │\n",
    "└─────────────┬───────────────────────────┘\n",
    "              │\n",
    "              ├─────────────────────────────┐\n",
    "              │                             │\n",
    "              ▼                             ▼\n",
    "    ┌─────────────────┐         ┌──────────────────┐\n",
    "    │ Texto Simple    │         │ Texto Enriquecido│\n",
    "    │ (sin modificar) │         │ (con prefijos)   │\n",
    "    └────────┬────────┘         └────────┬─────────┘\n",
    "             │                           │\n",
    "    ┌────────┴────────┐         ┌────────┴─────────┐\n",
    "    ▼                 ▼         ▼                  ▼\n",
    "corpus_simple   textos_planos  corpus_enriquecido  corpus_rag\n",
    "```\n",
    "\n",
    "### 4.2 Función: optimizar_para_embeddings()\n",
    "\n",
    "**Propósito:**\n",
    "- Convertir CSV a formato JSON estructurado\n",
    "- Opción de enriquecimiento textual\n",
    "- Preservar metadata relevante\n",
    "\n",
    "**Parámetros:**\n",
    "- `csv_path`: Ruta del archivo CSV de entrada\n",
    "- `output_json`: Ruta del archivo JSON de salida\n",
    "- `incluir_metadata`: Boolean para enriquecimiento\n",
    "\n",
    "**Proceso:**\n",
    "1. Carga CSV con pandas\n",
    "2. Itera sobre cada fila\n",
    "3. Extrae y limpia texto\n",
    "4. Si incluir_metadata=True: añade prefijos [Tema] [Sentimiento]\n",
    "5. Estructura en formato JSON\n",
    "6. Guarda resultado\n",
    "\n",
    "### 4.3 Función: extraer_solo_textos()\n",
    "\n",
    "**Propósito:**\n",
    "- Extraer únicamente el contenido textual\n",
    "- Formato minimalista una línea por documento\n",
    "\n",
    "**Características:**\n",
    "- Sin estructura JSON\n",
    "- Sin metadatos\n",
    "- Limpieza de espacios\n",
    "- Salida en texto plano\n",
    "\n",
    "### 4.4 Función: crear_corpus_busqueda()\n",
    "\n",
    "**Propósito:**\n",
    "- Generar formato especializado para RAG\n",
    "- Combinar ventajas de ambos enfoques\n",
    "\n",
    "**Enriquecimientos:**\n",
    "- Dos versiones del contenido (simple y enriquecido)\n",
    "- Engagement combinado (likes + reposts)\n",
    "- ID descriptivo con prefijo\n",
    "- Formato legible por humanos en enriched_content\n",
    "\n",
    "### 4.5 Función: stats_dataset()\n",
    "\n",
    "**Propósito:**\n",
    "- Análisis exploratorio del dataset\n",
    "- Validación de calidad de datos\n",
    "\n",
    "**Métricas Reportadas:**\n",
    "- Total de documentos\n",
    "- Distribución de temas\n",
    "- Distribución de sentimientos\n",
    "- Promedios de engagement\n",
    "- Longitud promedio de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6168d5",
   "metadata": {},
   "source": [
    "## 5. Embeddings y Búsqueda Semántica\n",
    "\n",
    "### 5.1 Concepto de Embeddings\n",
    "\n",
    "Los embeddings son representaciones vectoriales densas de texto:\n",
    "\n",
    "**Proceso:**\n",
    "```\n",
    "Texto → Modelo de Embedding → Vector [768 dimensiones]\n",
    "\"La IA cambia...\" → [0.23, -0.45, 0.12, ...]\n",
    "```\n",
    "\n",
    "**Propiedades:**\n",
    "- Textos similares tienen vectores cercanos\n",
    "- Capturan significado semántico\n",
    "- Dimensionalidad típica: 384-1536\n",
    "- Permiten búsqueda por similitud\n",
    "\n",
    "### 5.2 Modelos de Embedding Populares\n",
    "\n",
    "| Modelo | Dimensiones | Idioma | Uso |\n",
    "|--------|-------------|--------|-----|\n",
    "| sentence-transformers/paraphrase-multilingual | 768 | Multi | General |\n",
    "| text-embedding-ada-002 (OpenAI) | 1536 | Multi | Alta calidad |\n",
    "| intfloat/multilingual-e5-large | 1024 | Multi | Balance |\n",
    "| BAAI/bge-m3 | 1024 | Multi | Estado del arte |\n",
    "\n",
    "### 5.3 Estrategias de Búsqueda\n",
    "\n",
    "#### Similitud Coseno\n",
    "\n",
    "Métrica más común para comparar embeddings:\n",
    "\n",
    "```\n",
    "similitud = (A · B) / (||A|| * ||B||)\n",
    "Rango: [-1, 1] donde 1 es idéntico\n",
    "```\n",
    "\n",
    "#### Distancia Euclidiana\n",
    "\n",
    "Alternativa basada en distancia geométrica:\n",
    "\n",
    "```\n",
    "distancia = √Σ(ai - bi)²\n",
    "Menor distancia = mayor similitud\n",
    "```\n",
    "\n",
    "#### Producto Interno\n",
    "\n",
    "Más rápido pero requiere vectores normalizados:\n",
    "\n",
    "```\n",
    "similitud = Σ(ai * bi)\n",
    "```\n",
    "\n",
    "### 5.4 Workflow RAG Completo\n",
    "\n",
    "```\n",
    "1. INDEXACIÓN (Offline)\n",
    "   ├─ Cargar corpus_rag.json\n",
    "   ├─ Generar embeddings para cada documento\n",
    "   ├─ Almacenar en base vectorial (FAISS, Chroma, etc.)\n",
    "   └─ Crear índice para búsqueda rápida\n",
    "\n",
    "2. QUERY (Online)\n",
    "   ├─ Recibir pregunta del usuario\n",
    "   ├─ Generar embedding de la pregunta\n",
    "   ├─ Buscar top-k documentos más similares\n",
    "   └─ Recuperar documentos con metadata\n",
    "\n",
    "3. GENERACIÓN\n",
    "   ├─ Construir prompt con documentos recuperados\n",
    "   ├─ Enviar a LLM (GPT, Claude, Llama, etc.)\n",
    "   ├─ Generar respuesta fundamentada\n",
    "   └─ Citar fuentes cuando sea apropiado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c78493",
   "metadata": {},
   "source": [
    "## 6. Bases de Datos Vectoriales\n",
    "\n",
    "### 6.1 Opciones Populares\n",
    "\n",
    "#### FAISS (Facebook AI)\n",
    "\n",
    "**Características:**\n",
    "- Librería de código abierto\n",
    "- Extremadamente rápida\n",
    "- Requiere implementación manual de persistencia\n",
    "- Ideal para experimentación\n",
    "\n",
    "**Ventajas:**\n",
    "- Búsqueda en milisegundos\n",
    "- Soporta millones de vectores\n",
    "- Múltiples algoritmos de indexación\n",
    "- Sin dependencias externas\n",
    "\n",
    "#### ChromaDB\n",
    "\n",
    "**Características:**\n",
    "- Base de datos especializada en embeddings\n",
    "- Persistencia automática\n",
    "- API simple y pythónica\n",
    "- Integración con LangChain\n",
    "\n",
    "**Ventajas:**\n",
    "- Fácil de usar\n",
    "- Maneja metadata automáticamente\n",
    "- Filtraje por metadata\n",
    "- Escalabilidad moderada\n",
    "\n",
    "#### Pinecone\n",
    "\n",
    "**Características:**\n",
    "- Servicio cloud especializado\n",
    "- Escalabilidad automática\n",
    "- API RESTful\n",
    "- Pago por uso\n",
    "\n",
    "**Ventajas:**\n",
    "- Sin infraestructura\n",
    "- Alta disponibilidad\n",
    "- Actualizaciones en tiempo real\n",
    "- Soporte empresarial\n",
    "\n",
    "#### Weaviate\n",
    "\n",
    "**Características:**\n",
    "- Base de datos vectorial open source\n",
    "- GraphQL API\n",
    "- Búsqueda híbrida (vectorial + keyword)\n",
    "- Self-hosted o cloud\n",
    "\n",
    "**Ventajas:**\n",
    "- Combina búsqueda semántica y tradicional\n",
    "- Esquema flexible\n",
    "- Multitenancy\n",
    "- Modelos de embedding integrados\n",
    "\n",
    "### 6.2 Comparación de Rendimiento\n",
    "\n",
    "| Base de Datos | Velocidad | Escalabilidad | Complejidad | Costo |\n",
    "|---------------|-----------|---------------|-------------|-------|\n",
    "| FAISS | Muy alta | Alta | Media | Gratis |\n",
    "| ChromaDB | Alta | Media | Baja | Gratis |\n",
    "| Pinecone | Alta | Muy alta | Baja | Pago |\n",
    "| Weaviate | Alta | Alta | Media | Gratis/Pago |\n",
    "\n",
    "### 6.3 Integración con Formatos\n",
    "\n",
    "**Para corpus_simple.json:**\n",
    "```python\n",
    "# Indexar solo el texto\n",
    "vectorstore.add_texts(\n",
    "    texts=[doc['texto'] for doc in corpus],\n",
    "    metadatas=[doc['metadata'] for doc in corpus]\n",
    ")\n",
    "```\n",
    "\n",
    "**Para corpus_rag.json:**\n",
    "```python\n",
    "# Elección entre simple o enriquecido\n",
    "vectorstore.add_texts(\n",
    "    texts=[doc['enriched_content'] for doc in corpus],\n",
    "    metadatas=[doc['metadata'] for doc in corpus],\n",
    "    ids=[doc['id'] for doc in corpus]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab4e4c",
   "metadata": {},
   "source": [
    "## 7. Optimizaciones y Estrategias\n",
    "\n",
    "### 7.1 Enriquecimiento Contextual\n",
    "\n",
    "**Ventajas:**\n",
    "- Mejora precisión en búsquedas categorizadas\n",
    "- Ayuda al modelo a entender contexto\n",
    "- Permite filtrado implícito\n",
    "\n",
    "**Desventajas:**\n",
    "- Puede sesgar la búsqueda\n",
    "- Incrementa longitud de documentos\n",
    "- Puede afectar similitud entre categorías\n",
    "\n",
    "**Cuándo Usar:**\n",
    "- Dataset con categorías bien definidas\n",
    "- Queries que mencionan temas específicos\n",
    "- Necesidad de filtrado por metadata\n",
    "\n",
    "### 7.2 Chunking (Segmentación)\n",
    "\n",
    "Para documentos largos, considerar segmentación:\n",
    "\n",
    "**Estrategias:**\n",
    "\n",
    "```python\n",
    "# Por longitud fija\n",
    "chunks = [texto[i:i+500] for i in range(0, len(texto), 400)]\n",
    "# Overlap de 100 caracteres\n",
    "\n",
    "# Por oraciones\n",
    "sentences = texto.split('. ')\n",
    "chunks = ['. '.join(sentences[i:i+5]) for i in range(0, len(sentences), 4)]\n",
    "# Grupos de 5 oraciones con overlap de 1\n",
    "\n",
    "# Por párrafos semánticos\n",
    "# Usa NLP para detectar cambios de tema\n",
    "```\n",
    "\n",
    "**Consideraciones:**\n",
    "- Chunks más pequeños: mayor precisión, menos contexto\n",
    "- Chunks más grandes: más contexto, menos precisión\n",
    "- Overlap previene pérdida de información en fronteras\n",
    "\n",
    "### 7.3 Filtrado por Metadata\n",
    "\n",
    "Combinar búsqueda semántica con filtros estructurados:\n",
    "\n",
    "```python\n",
    "# Ejemplo con ChromaDB\n",
    "results = collection.query(\n",
    "    query_texts=[\"pregunta del usuario\"],\n",
    "    where={\"tema\": \"Generación Z y crisis de sentido\"},\n",
    "    n_results=5\n",
    ")\n",
    "```\n",
    "\n",
    "**Ventajas:**\n",
    "- Restringe búsqueda a subconjunto relevante\n",
    "- Mejora precisión en dominios específicos\n",
    "- Reduce ruido en resultados\n",
    "\n",
    "### 7.4 Reranking\n",
    "\n",
    "Mejora los resultados iniciales:\n",
    "\n",
    "**Proceso:**\n",
    "1. Recuperar top-20 con búsqueda vectorial rápida\n",
    "2. Aplicar modelo más sofisticado a los 20\n",
    "3. Reordenar y seleccionar top-5 finales\n",
    "\n",
    "**Modelos de Reranking:**\n",
    "- Cross-encoders (más precisos pero lentos)\n",
    "- Scoring por engagement\n",
    "- Diversidad temática\n",
    "- Recencia temporal\n",
    "\n",
    "### 7.5 Híbrido: Vectorial + Keyword\n",
    "\n",
    "Combina búsqueda semántica con búsqueda tradicional:\n",
    "\n",
    "```\n",
    "Score_final = α * Score_vectorial + (1-α) * Score_BM25\n",
    "```\n",
    "\n",
    "**Ventajas:**\n",
    "- Captura matches exactos importantes\n",
    "- Complementa debilidades de cada método\n",
    "- Mejor para queries con términos técnicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598a955",
   "metadata": {},
   "source": [
    "## 8. Casos de Uso Específicos\n",
    "\n",
    "### 8.1 Asistente Conversacional Temático\n",
    "\n",
    "**Escenario:**\n",
    "- Chatbot que responde sobre temas generacionales\n",
    "- Necesita fundamentar respuestas en opiniones reales\n",
    "- Debe citar fuentes cuando sea relevante\n",
    "\n",
    "**Configuración Recomendada:**\n",
    "- Formato: `corpus_rag.json` con enriched_content\n",
    "- Base vectorial: ChromaDB\n",
    "- Top-k: 3-5 documentos\n",
    "- Reranking por engagement\n",
    "\n",
    "**Prompt Template:**\n",
    "```\n",
    "Contexto recuperado:\n",
    "{documento_1}\n",
    "{documento_2}\n",
    "{documento_3}\n",
    "\n",
    "Pregunta del usuario: {query}\n",
    "\n",
    "Instrucciones: Responde basándote en el contexto proporcionado.\n",
    "Si mencionas ideas del contexto, cita la fuente.\n",
    "```\n",
    "\n",
    "### 8.2 Análisis de Sentimientos por Tema\n",
    "\n",
    "**Escenario:**\n",
    "- Investigación sobre opiniones generacionales\n",
    "- Necesita agrupar documentos por tema y sentimiento\n",
    "- Busca patrones en el discurso\n",
    "\n",
    "**Configuración Recomendada:**\n",
    "- Formato: `corpus_simple.json`\n",
    "- Filtrado por metadata (tema + sentimiento)\n",
    "- Clustering adicional con embeddings\n",
    "\n",
    "### 8.3 Sistema de Recomendación de Contenido\n",
    "\n",
    "**Escenario:**\n",
    "- Sugerir publicaciones similares\n",
    "- Basado en el contenido que un usuario está leyendo\n",
    "- Considera engagement para ordenar\n",
    "\n",
    "**Configuración Recomendada:**\n",
    "- Formato: `corpus_rag.json`\n",
    "- Búsqueda por similitud del documento actual\n",
    "- Reranking por engagement y diversidad temática\n",
    "- Excluir mismo tema si se busca variedad\n",
    "\n",
    "### 8.4 Búsqueda Semántica Directa\n",
    "\n",
    "**Escenario:**\n",
    "- Motor de búsqueda interno\n",
    "- Usuario busca contenido específico\n",
    "- No necesita generación, solo recuperación\n",
    "\n",
    "**Configuración Recomendada:**\n",
    "- Formato: `corpus_simple.json`\n",
    "- Búsqueda híbrida (vectorial + BM25)\n",
    "- Mostrar snippets con highlighting\n",
    "- Ordenar por relevancia y fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5977e0af",
   "metadata": {},
   "source": [
    "## 9. Mejores Prácticas\n",
    "\n",
    "### 9.1 Preparación de Datos\n",
    "\n",
    "**Limpieza:**\n",
    "- Eliminar duplicados exactos\n",
    "- Corregir errores de encoding\n",
    "- Normalizar espacios en blanco\n",
    "- Verificar integridad de metadatos\n",
    "\n",
    "**Validación:**\n",
    "- Confirmar que todos los campos requeridos existen\n",
    "- Verificar tipos de datos\n",
    "- Detectar valores nulos o inconsistentes\n",
    "- Validar rangos numéricos\n",
    "\n",
    "### 9.2 Elección de Formato\n",
    "\n",
    "**Usar corpus_simple.json cuando:**\n",
    "- Modelo de embeddings maneja metadata separadamente\n",
    "- Necesitas máxima pureza semántica\n",
    "- Experimentas con diferentes enriquecimientos\n",
    "\n",
    "**Usar corpus_enriquecido.json cuando:**\n",
    "- Queries mencionan categorías explícitamente\n",
    "- Dataset tiene categorías muy distintas\n",
    "- Necesitas filtrado implícito\n",
    "\n",
    "**Usar corpus_rag.json cuando:**\n",
    "- Implementas sistema RAG completo\n",
    "- Necesitas flexibilidad para elegir versión\n",
    "- Requieres métricas adicionales (engagement)\n",
    "\n",
    "### 9.3 Optimización de Búsqueda\n",
    "\n",
    "**Top-k Apropiado:**\n",
    "- Queries específicas: k=3-5\n",
    "- Queries amplias: k=10-20\n",
    "- Con reranking: recuperar 2-3x más\n",
    "\n",
    "**Threshold de Similitud:**\n",
    "- Establecer mínimo de similitud (ej. 0.7)\n",
    "- Si no hay matches suficientes, indicar al usuario\n",
    "- Evitar respuestas basadas en documentos irrelevantes\n",
    "\n",
    "### 9.4 Actualización del Corpus\n",
    "\n",
    "**Estrategias:**\n",
    "- Incremental: Añadir nuevos documentos sin reindexar todo\n",
    "- Batch: Reindexar periódicamente (semanal/mensual)\n",
    "- Versioning: Mantener múltiples versiones del índice\n",
    "\n",
    "**Consideraciones:**\n",
    "- Reindexar puede tardar con corpus grandes\n",
    "- Mantener consistencia entre datos y embeddings\n",
    "- Planificar ventanas de mantenimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d7801",
   "metadata": {},
   "source": [
    "## 10. Evaluación de Sistemas RAG\n",
    "\n",
    "### 10.1 Métricas de Recuperación\n",
    "\n",
    "**Precisión (Precision):**\n",
    "```\n",
    "Precisión = Documentos Relevantes Recuperados / Total Documentos Recuperados\n",
    "```\n",
    "- Mide calidad de los resultados\n",
    "- Alta precisión: pocos falsos positivos\n",
    "\n",
    "**Recall (Cobertura):**\n",
    "```\n",
    "Recall = Documentos Relevantes Recuperados / Total Documentos Relevantes\n",
    "```\n",
    "- Mide completitud de los resultados\n",
    "- Alto recall: no se pierden documentos importantes\n",
    "\n",
    "**F1-Score:**\n",
    "```\n",
    "F1 = 2 * (Precisión * Recall) / (Precisión + Recall)\n",
    "```\n",
    "- Balance entre precisión y recall\n",
    "\n",
    "**MRR (Mean Reciprocal Rank):**\n",
    "```\n",
    "MRR = (1/N) * Σ(1/rank_primer_relevante)\n",
    "```\n",
    "- Mide qué tan arriba aparece el primer resultado relevante\n",
    "\n",
    "### 10.2 Métricas de Generación\n",
    "\n",
    "**Faithfulness:**\n",
    "- Respuesta fundamentada en documentos recuperados\n",
    "- Sin alucinaciones o información externa\n",
    "\n",
    "**Answer Relevance:**\n",
    "- Respuesta directamente relacionada con la pregunta\n",
    "- No divaga ni incluye información innecesaria\n",
    "\n",
    "**Context Relevance:**\n",
    "- Documentos recuperados son pertinentes\n",
    "- No contienen ruido irrelevante\n",
    "\n",
    "### 10.3 Evaluación Práctica\n",
    "\n",
    "**Dataset de Prueba:**\n",
    "- Crear conjunto de queries representativas\n",
    "- Anotar documentos relevantes para cada query\n",
    "- Evaluar respuestas generadas\n",
    "\n",
    "**Ejemplo:**\n",
    "```python\n",
    "test_queries = [\n",
    "    {\n",
    "        \"query\": \"¿Cómo afecta la IA a nuestra autonomía?\",\n",
    "        \"relevant_docs\": [\"doc_5\", \"doc_13\", \"doc_49\"],\n",
    "        \"expected_themes\": [\"IA y pérdida de autonomía humana\"]\n",
    "    },\n",
    "    # más casos...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a5796",
   "metadata": {},
   "source": [
    "## 11. Arquitectura de Sistema RAG Completo\n",
    "\n",
    "### 11.1 Componentes del Sistema\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│              SISTEMA RAG COMPLETO                   │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "\n",
    "┌──────────────┐       ┌──────────────┐       ┌──────────────┐\n",
    "│   Ingesta    │──────▶│  Indexación  │──────▶│ Almacenamiento│\n",
    "└──────────────┘       └──────────────┘       └──────────────┘\n",
    "      │                      │                       │\n",
    "      │                      │                       │\n",
    " CSV Parser           Embedding Model          Vector DB\n",
    " Limpieza            (sentence-transformers)   (ChromaDB)\n",
    " Validación          Batch processing          Persistencia\n",
    "\n",
    "                            ▼\n",
    "\n",
    "┌──────────────┐       ┌──────────────┐       ┌──────────────┐\n",
    "│    Query     │──────▶│  Retrieval   │──────▶│  Generation  │\n",
    "└──────────────┘       └──────────────┘       └──────────────┘\n",
    "      │                      │                       │\n",
    "      │                      │                       │\n",
    " User Input           Similarity Search         LLM\n",
    " Embedding            Top-k Selection          Prompt Builder\n",
    " Preprocessing        Reranking                Response Format\n",
    "\n",
    "                            ▼\n",
    "\n",
    "                    ┌──────────────┐\n",
    "                    │   Response   │\n",
    "                    └──────────────┘\n",
    "                          │\n",
    "                    Answer + Sources\n",
    "                    Confidence Score\n",
    "                    Citations\n",
    "```\n",
    "\n",
    "### 11.2 Implementación con LangChain\n",
    "\n",
    "```python\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 1. Cargar embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# 2. Crear vector store\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# 3. Cargar documentos\n",
    "import json\n",
    "with open('corpus_rag.json') as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "# 4. Indexar\n",
    "vectorstore.add_texts(\n",
    "    texts=[d['enriched_content'] for d in docs],\n",
    "    metadatas=[d['metadata'] for d in docs],\n",
    "    ids=[d['id'] for d in docs]\n",
    ")\n",
    "\n",
    "# 5. Crear cadena RAG\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    ")\n",
    "\n",
    "# 6. Query\n",
    "response = qa_chain.run(\"¿Cómo afecta la IA a la autonomía humana?\")\n",
    "```\n",
    "\n",
    "### 11.3 Stack Tecnológico Recomendado\n",
    "\n",
    "**Backend:**\n",
    "- FastAPI o Flask para API\n",
    "- Celery para procesamiento asíncrono\n",
    "- Redis para caché\n",
    "\n",
    "**Storage:**\n",
    "- ChromaDB o Weaviate para vectores\n",
    "- PostgreSQL para metadata estructurada\n",
    "- S3 para respaldo de datos\n",
    "\n",
    "**Embeddings:**\n",
    "- sentence-transformers local\n",
    "- OpenAI embeddings para producción\n",
    "- Cohere embeddings como alternativa\n",
    "\n",
    "**LLM:**\n",
    "- OpenAI GPT-4 para calidad máxima\n",
    "- Anthropic Claude para largo contexto\n",
    "- Llama 2/3 local para privacidad"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
