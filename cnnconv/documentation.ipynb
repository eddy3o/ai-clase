{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ea29c3",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Este documento presenta un sistema completo de clasificación de imágenes de animales utilizando Redes Neuronales Convolucionales (CNN). El sistema es capaz de identificar cinco categorías distintas de animales: catarina, gato, hormiga, perro y tortuga.\n",
    "\n",
    "### 1.1 Objetivos del Sistema\n",
    "\n",
    "- Entrenar un modelo CNN robusto para clasificación multiclase\n",
    "- Implementar técnicas de regularización para prevenir sobreajuste\n",
    "- Proporcionar un sistema de inferencia eficiente y confiable\n",
    "- Visualizar el proceso de aprendizaje y resultados de predicción\n",
    "\n",
    "### 1.2 Componentes Principales\n",
    "\n",
    "El sistema consta de dos módulos independientes:\n",
    "\n",
    "1. **Módulo de Entrenamiento**: Construcción y entrenamiento del modelo CNN\n",
    "2. **Módulo de Inferencia**: Clasificación de nuevas imágenes usando el modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c46844",
   "metadata": {},
   "source": [
    "## 2. Arquitectura de Red Neuronal Convolucional\n",
    "\n",
    "### 2.1 Concepto de CNN\n",
    "\n",
    "Las Redes Neuronales Convolucionales son arquitecturas especializadas en el procesamiento de datos con estructura de cuadrícula, como imágenes. A diferencia de las redes neuronales tradicionales, las CNN:\n",
    "\n",
    "- Preservan la relación espacial entre píxeles\n",
    "- Reducen la cantidad de parámetros mediante pesos compartidos\n",
    "- Extraen características jerárquicas automáticamente\n",
    "\n",
    "### 2.2 Estructura de la Arquitectura\n",
    "\n",
    "La red implementada sigue un diseño de cuatro bloques convolucionales con complejidad creciente:\n",
    "\n",
    "#### Bloque Convolucional 1\n",
    "- **Filtros**: 32\n",
    "- **Resolución**: 128x128 → 64x64\n",
    "- **Función**: Detecta características básicas (bordes, colores, gradientes)\n",
    "\n",
    "#### Bloque Convolucional 2\n",
    "- **Filtros**: 64\n",
    "- **Resolución**: 64x64 → 32x32\n",
    "- **Función**: Detecta texturas y formas geométricas simples\n",
    "\n",
    "#### Bloque Convolucional 3\n",
    "- **Filtros**: 128\n",
    "- **Resolución**: 32x32 → 16x16\n",
    "- **Función**: Identifica estructuras complejas (partes de animales)\n",
    "\n",
    "#### Bloque Convolucional 4\n",
    "- **Filtros**: 128\n",
    "- **Resolución**: 16x16 → 8x8\n",
    "- **Función**: Reconoce objetos completos y contextos\n",
    "\n",
    "### 2.3 Clasificador Denso\n",
    "\n",
    "Después de la extracción de características, la red utiliza capas densas para la clasificación:\n",
    "\n",
    "```\n",
    "Flatten: (8, 8, 128) → (8192,)\n",
    "Dense 1: 8192 → 512 neuronas\n",
    "Dense 2: 512 → 128 neuronas\n",
    "Output: 128 → 5 neuronas (softmax)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c1c8ea",
   "metadata": {},
   "source": [
    "## 3. Configuración de Hiperparámetros\n",
    "\n",
    "### 3.1 Parámetros de Entrada\n",
    "\n",
    "| Parámetro | Valor | Descripción |\n",
    "|-----------|-------|-------------|\n",
    "| `INPUT_DIMENSIONS` | 128 | Resolución de entrada (128x128 píxeles) |\n",
    "| `COLOR_CHANNELS` | 3 | Imágenes RGB con 3 canales |\n",
    "| `SAMPLES_PER_BATCH` | 32 | Tamaño de lote para gradiente descendente |\n",
    "\n",
    "### 3.2 Parámetros de Entrenamiento\n",
    "\n",
    "| Parámetro | Valor | Propósito |\n",
    "|-----------|-------|----------|\n",
    "| `TRAINING_ITERATIONS` | 45 | Número máximo de épocas |\n",
    "| `INITIAL_LEARNING_RATE` | 0.001 | Tasa de aprendizaje inicial |\n",
    "| `VALIDATION_SPLIT_RATIO` | 0.2 | 20% de datos para validación |\n",
    "\n",
    "### 3.3 Parámetros de Regularización\n",
    "\n",
    "| Parámetro | Valor | Aplicación |\n",
    "|-----------|-------|------------|\n",
    "| `DROPOUT_LIGHT` | 0.3 | Dropout en capas convolucionales |\n",
    "| `DROPOUT_HEAVY` | 0.5 | Dropout antes de clasificación |\n",
    "| `LR_REDUCTION_FACTOR` | 0.5 | Factor de reducción del learning rate |\n",
    "| `EARLY_STOP_PATIENCE` | 5 | Épocas sin mejora antes de detener |\n",
    "| `LR_PLATEAU_PATIENCE` | 3 | Épocas sin mejora antes de reducir LR |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480e522",
   "metadata": {},
   "source": [
    "## 4. Pipeline de Datos y Augmentación\n",
    "\n",
    "### 4.1 Generadores de Datos\n",
    "\n",
    "El sistema utiliza `ImageDataGenerator` de Keras para gestionar el flujo de datos de manera eficiente sin cargar todas las imágenes en memoria simultáneamente.\n",
    "\n",
    "### 4.2 Técnicas de Augmentación\n",
    "\n",
    "La augmentación de datos es crucial para prevenir sobreajuste y mejorar la generalización:\n",
    "\n",
    "#### Transformaciones Aplicadas\n",
    "\n",
    "| Transformación | Rango | Efecto |\n",
    "|----------------|-------|--------|\n",
    "| Rotación | ±20° | Invarianza a orientación |\n",
    "| Desplazamiento Horizontal | ±20% | Robustez ante posicionamiento |\n",
    "| Desplazamiento Vertical | ±20% | Tolerancia a centrado |\n",
    "| Volteo Horizontal | Aleatorio | Simetría de animales |\n",
    "| Zoom | ±20% | Invarianza a escala |\n",
    "\n",
    "### 4.3 Normalización\n",
    "\n",
    "Todos los valores de píxeles se normalizan al rango [0, 1] mediante:\n",
    "\n",
    "```\n",
    "pixel_normalizado = pixel_original / 255.0\n",
    "```\n",
    "\n",
    "Esto acelera la convergencia y estabiliza el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e281f75",
   "metadata": {},
   "source": [
    "## 5. Proceso de Entrenamiento\n",
    "\n",
    "### 5.1 Optimizador Adam\n",
    "\n",
    "El algoritmo de optimización Adam combina las ventajas de dos métodos:\n",
    "\n",
    "- **Momentum**: Aceleración del descenso en direcciones consistentes\n",
    "- **RMSprop**: Adaptación de tasas de aprendizaje por parámetro\n",
    "\n",
    "### 5.2 Función de Pérdida\n",
    "\n",
    "Se utiliza **Categorical Crossentropy** para clasificación multiclase:\n",
    "\n",
    "- Mide la discrepancia entre distribuciones de probabilidad\n",
    "- Penaliza predicciones incorrectas proporcionalmente a su confianza\n",
    "- Compatible con activación softmax en la capa de salida\n",
    "\n",
    "### 5.3 Callbacks Adaptativos\n",
    "\n",
    "#### ReduceLROnPlateau\n",
    "\n",
    "Reduce el learning rate cuando el progreso se estanca:\n",
    "\n",
    "```python\n",
    "Monitorea: val_loss\n",
    "Acción: LR = LR × 0.5\n",
    "Paciencia: 3 épocas\n",
    "LR mínimo: 1e-7\n",
    "```\n",
    "\n",
    "#### EarlyStopping\n",
    "\n",
    "Detiene el entrenamiento cuando no hay mejoras significativas:\n",
    "\n",
    "```python\n",
    "Monitorea: val_loss\n",
    "Paciencia: 5 épocas\n",
    "Delta mínimo: 0.001\n",
    "Acción: Restaura mejores pesos\n",
    "```\n",
    "\n",
    "### 5.4 Flujo de Entrenamiento\n",
    "\n",
    "Cada época ejecuta:\n",
    "\n",
    "1. **Forward Pass**: Propagación de datos por la red\n",
    "2. **Cálculo de Pérdida**: Comparación con etiquetas reales\n",
    "3. **Backward Pass**: Cálculo de gradientes\n",
    "4. **Actualización de Pesos**: Aplicación de gradientes\n",
    "5. **Validación**: Evaluación en datos no vistos\n",
    "6. **Callbacks**: Ajustes adaptativos si es necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2016c2c",
   "metadata": {},
   "source": [
    "## 6. Técnicas de Regularización\n",
    "\n",
    "### 6.1 Dropout\n",
    "\n",
    "Durante el entrenamiento, Dropout desactiva aleatoriamente un porcentaje de neuronas:\n",
    "\n",
    "**Beneficios:**\n",
    "- Previene co-adaptación de neuronas\n",
    "- Simula entrenamiento de múltiples redes\n",
    "- Reduce sobreajuste significativamente\n",
    "\n",
    "**Estrategia de Aplicación:**\n",
    "- 30% en bloques convolucionales (características visuales)\n",
    "- 50% antes de clasificación (decisiones de alto nivel)\n",
    "\n",
    "### 6.2 MaxPooling\n",
    "\n",
    "Reduce la dimensionalidad espacial seleccionando el valor máximo en ventanas 2x2:\n",
    "\n",
    "**Efectos:**\n",
    "- Disminuye parámetros de la red\n",
    "- Introduce invarianza a pequeños desplazamientos\n",
    "- Conserva características más prominentes\n",
    "\n",
    "### 6.3 Activación LeakyReLU\n",
    "\n",
    "Variante de ReLU que permite pequeños valores negativos:\n",
    "\n",
    "```\n",
    "ReLU estándar: f(x) = max(0, x)\n",
    "LeakyReLU: f(x) = max(0.1x, x)\n",
    "```\n",
    "\n",
    "**Ventaja**: Evita el problema de \"neuronas muertas\" que nunca se activan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be21518b",
   "metadata": {},
   "source": [
    "## 7. Sistema de Clasificación\n",
    "\n",
    "### 7.1 Preprocesamiento de Imágenes\n",
    "\n",
    "El módulo de inferencia realiza un preprocesamiento cuidadoso:\n",
    "\n",
    "#### Paso 1: Conversión de Espacio de Color\n",
    "```\n",
    "OpenCV (BGR) → RGB estándar\n",
    "```\n",
    "\n",
    "#### Paso 2: Redimensionamiento Proporcional\n",
    "- Calcula factor de escala para ajustar a 128x128\n",
    "- Mantiene aspect ratio original\n",
    "- Evita distorsión de la imagen\n",
    "\n",
    "#### Paso 3: Padding Inteligente\n",
    "- Crea canvas negro de 128x128\n",
    "- Centra la imagen redimensionada\n",
    "- Rellena espacios vacíos con negro\n",
    "\n",
    "#### Paso 4: Normalización y Batching\n",
    "```python\n",
    "imagen_normalizada = imagen / 255.0\n",
    "batch = np.expand_dims(imagen_normalizada, axis=0)\n",
    "```\n",
    "\n",
    "### 7.2 Proceso de Inferencia\n",
    "\n",
    "La clasificación ejecuta en tres etapas:\n",
    "\n",
    "1. **Propagación**: La imagen procesada atraviesa toda la red\n",
    "2. **Softmax**: Convierte scores en probabilidades que suman 1.0\n",
    "3. **Argmax**: Selecciona la clase con mayor probabilidad\n",
    "\n",
    "### 7.3 Interpretación de Resultados\n",
    "\n",
    "El sistema retorna:\n",
    "\n",
    "- **Categoría predicha**: Clase con mayor probabilidad\n",
    "- **Vector de probabilidades**: Distribución completa sobre las 5 clases\n",
    "- **Confianza**: Probabilidad de la clase predicha (0-100%)\n",
    "\n",
    "#### Niveles de Confianza\n",
    "\n",
    "| Confianza | Interpretación |\n",
    "|-----------|----------------|\n",
    "| 90-100% | Predicción muy confiable |\n",
    "| 70-89% | Predicción confiable |\n",
    "| 50-69% | Predicción moderada |\n",
    "| < 50% | Predicción incierta |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71b784",
   "metadata": {},
   "source": [
    "## 8. Categorías de Clasificación\n",
    "\n",
    "### 8.1 Clases Implementadas\n",
    "\n",
    "El sistema identifica cinco categorías de animales:\n",
    "\n",
    "| Índice | Categoría | Características Distintivas |\n",
    "|--------|-----------|-----------------------------|\n",
    "| 0 | Catarina | Patrón de puntos, forma redonda, colores vivos |\n",
    "| 1 | Gato | Orejas puntiagudas, bigotes, ojos felinos |\n",
    "| 2 | Hormiga | Cuerpo segmentado, antenas, tamaño pequeño |\n",
    "| 3 | Perro | Orejas variadas, hocico, expresión facial |\n",
    "| 4 | Tortuga | Caparazón, cuello extensible, extremidades cortas |\n",
    "\n",
    "### 8.2 Desafíos de Clasificación\n",
    "\n",
    "**Variabilidad Intraclase:**\n",
    "- Diferentes razas de perros y gatos\n",
    "- Variaciones de tamaño y color\n",
    "- Ángulos y poses diversas\n",
    "\n",
    "**Similitudes Interclase:**\n",
    "- Gatos y perros pueden tener posturas similares\n",
    "- Iluminación puede afectar colores distintivos\n",
    "- Fondos complejos pueden confundir la red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7e215",
   "metadata": {},
   "source": [
    "## 9. Visualización y Análisis\n",
    "\n",
    "### 9.1 Métricas de Entrenamiento\n",
    "\n",
    "El sistema registra y visualiza:\n",
    "\n",
    "#### Precisión (Accuracy)\n",
    "- **Entrenamiento**: Rendimiento en datos de entrenamiento\n",
    "- **Validación**: Rendimiento en datos no vistos\n",
    "- **Interpretación**: Porcentaje de predicciones correctas\n",
    "\n",
    "#### Pérdida (Loss)\n",
    "- **Entrenamiento**: Error en conjunto de entrenamiento\n",
    "- **Validación**: Error en conjunto de validación\n",
    "- **Interpretación**: Valores menores indican mejor ajuste\n",
    "\n",
    "### 9.2 Diagnóstico de Overfitting\n",
    "\n",
    "**Señales de Sobreajuste:**\n",
    "- Precisión de entrenamiento >> Precisión de validación\n",
    "- Pérdida de validación aumenta mientras la de entrenamiento disminuye\n",
    "- Brecha creciente entre curvas de entrenamiento y validación\n",
    "\n",
    "**Señales de Buen Ajuste:**\n",
    "- Curvas de entrenamiento y validación convergen\n",
    "- Ambas métricas mejoran consistentemente\n",
    "- Brecha pequeña entre entrenamiento y validación\n",
    "\n",
    "### 9.3 Visualización de Predicciones\n",
    "\n",
    "El sistema muestra:\n",
    "- Imagen original en tamaño completo\n",
    "- Etiqueta de categoría predicha\n",
    "- Overlay con fondo negro semitransparente para legibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45dccc",
   "metadata": {},
   "source": [
    "## 10. Persistencia del Modelo\n",
    "\n",
    "### 10.1 Formato HDF5\n",
    "\n",
    "El modelo se guarda en formato `.h5` que incluye:\n",
    "\n",
    "```\n",
    "animal_classifier_optimized.h5:\n",
    "├── Arquitectura completa de la red\n",
    "├── Pesos de todas las capas\n",
    "├── Configuración del optimizador\n",
    "└── Estado del entrenamiento\n",
    "```\n",
    "\n",
    "### 10.2 Historial de Entrenamiento\n",
    "\n",
    "El archivo `training_history.pkl` almacena:\n",
    "\n",
    "- Precisión por época (entrenamiento y validación)\n",
    "- Pérdida por época (entrenamiento y validación)\n",
    "- Valores de learning rate ajustados\n",
    "- Timestamp de cada época\n",
    "\n",
    "### 10.3 Ventajas de la Persistencia\n",
    "\n",
    "**Reutilización:**\n",
    "- No requiere reentrenamiento para inferencia\n",
    "- Carga rápida del modelo completo\n",
    "\n",
    "**Reproducibilidad:**\n",
    "- Resultados consistentes en diferentes ejecuciones\n",
    "- Permite auditoría de predicciones\n",
    "\n",
    "**Transfer Learning:**\n",
    "- Modelo base para nuevas tareas relacionadas\n",
    "- Fine-tuning con datos adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15781180",
   "metadata": {},
   "source": [
    "## 11. Implementación Práctica\n",
    "\n",
    "### 11.1 Estructura de Directorios\n",
    "\n",
    "```\n",
    "proyecto/\n",
    "├── animals-dataset/\n",
    "│   ├── catarina/\n",
    "│   ├── gato/\n",
    "│   ├── hormiga/\n",
    "│   ├── perro/\n",
    "│   └── tortuga/\n",
    "├── test-images/\n",
    "├── script.py (entrenamiento)\n",
    "├── test.py (inferencia)\n",
    "└── animal_classifier_optimized.h5\n",
    "```\n",
    "\n",
    "### 11.2 Flujo de Trabajo\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "```python\n",
    "trainer = NeuralNetworkTrainer(dataset_directory)\n",
    "trainer.run_complete_pipeline()\n",
    "```\n",
    "\n",
    "Ejecuta:\n",
    "1. Configuración de generadores\n",
    "2. Construcción de arquitectura\n",
    "3. Entrenamiento con callbacks\n",
    "4. Guardado de modelo\n",
    "5. Generación de visualizaciones\n",
    "\n",
    "#### Fase de Inferencia\n",
    "\n",
    "```python\n",
    "classifier = AnimalClassifier(model_path)\n",
    "category, probs, confidence = classifier.classify_image(image_path)\n",
    "```\n",
    "\n",
    "Ejecuta:\n",
    "1. Carga del modelo\n",
    "2. Preprocesamiento de imagen\n",
    "3. Predicción\n",
    "4. Visualización de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cd775",
   "metadata": {},
   "source": [
    "## 12. Consideraciones de Rendimiento\n",
    "\n",
    "### 12.1 Complejidad Computacional\n",
    "\n",
    "**Entrenamiento:**\n",
    "- Tiempo por época: Variable según tamaño del dataset\n",
    "- Memoria GPU: Aproximadamente 2-4 GB\n",
    "- Aceleración con GPU: 10-50x más rápido que CPU\n",
    "\n",
    "**Inferencia:**\n",
    "- Tiempo por imagen: < 100ms en GPU\n",
    "- Tiempo por imagen: 300-500ms en CPU\n",
    "- Memoria: < 1 GB\n",
    "\n",
    "### 12.2 Optimizaciones Implementadas\n",
    "\n",
    "**Reducción de Parámetros:**\n",
    "- MaxPooling reduce dimensiones espaciales\n",
    "- Pesos compartidos en convoluciones\n",
    "- Arquitectura eficiente sin capas redundantes\n",
    "\n",
    "**Eficiencia de Datos:**\n",
    "- Generadores para streaming de datos\n",
    "- No carga dataset completo en memoria\n",
    "- Procesamiento por lotes (batching)\n",
    "\n",
    "### 12.3 Escalabilidad\n",
    "\n",
    "El sistema puede escalar mediante:\n",
    "\n",
    "- **Más categorías**: Modificar capa de salida\n",
    "- **Más datos**: Ajustar parámetros de generadores\n",
    "- **Mayor resolución**: Incrementar INPUT_DIMENSIONS (requiere más memoria)\n",
    "- **Arquitectura profunda**: Agregar más bloques convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5c84f",
   "metadata": {},
   "source": [
    "## 13. Mejores Prácticas\n",
    "\n",
    "### 13.1 Preparación de Datos\n",
    "\n",
    "**Calidad del Dataset:**\n",
    "- Mínimo 100 imágenes por categoría\n",
    "- Variedad en poses, iluminación y fondos\n",
    "- Eliminación de imágenes corruptas o ambiguas\n",
    "- Balance entre categorías\n",
    "\n",
    "**Organización:**\n",
    "- Una carpeta por categoría\n",
    "- Nombres de archivo descriptivos\n",
    "- Formatos consistentes (JPG, PNG)\n",
    "\n",
    "### 13.2 Durante el Entrenamiento\n",
    "\n",
    "**Monitoreo:**\n",
    "- Observar curvas de pérdida y precisión\n",
    "- Verificar activación de callbacks\n",
    "- Revisar métricas cada época\n",
    "\n",
    "**Ajustes:**\n",
    "- Si overfitting: Aumentar dropout, más augmentación\n",
    "- Si underfitting: Reducir dropout, más épocas, arquitectura más compleja\n",
    "- Si convergencia lenta: Aumentar learning rate inicial\n",
    "\n",
    "### 13.3 En Producción\n",
    "\n",
    "**Validación:**\n",
    "- Probar con imágenes diversas\n",
    "- Verificar tiempos de respuesta\n",
    "- Manejar casos extremos (imágenes muy pequeñas, formato incorrecto)\n",
    "\n",
    "**Mantenimiento:**\n",
    "- Reentrenar periódicamente con nuevos datos\n",
    "- Monitorear precisión en producción\n",
    "- Mantener versiones anteriores del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e88671",
   "metadata": {},
   "source": [
    "## 14. Limitaciones y Extensiones\n",
    "\n",
    "### 14.1 Limitaciones Actuales\n",
    "\n",
    "**Técnicas:**\n",
    "- Resolución limitada a 128x128 (trade-off velocidad/detalle)\n",
    "- Cinco categorías fijas\n",
    "- Requiere imágenes individuales (no detecta múltiples animales)\n",
    "\n",
    "**Datos:**\n",
    "- Sensible a distribución del dataset de entrenamiento\n",
    "- Puede fallar con razas no vistas durante entrenamiento\n",
    "- Fondos muy diferentes pueden afectar rendimiento\n",
    "\n",
    "### 14.2 Extensiones Posibles\n",
    "\n",
    "**Arquitectura:**\n",
    "- Transfer Learning con modelos pre-entrenados (ResNet, VGG)\n",
    "- Attention mechanisms para enfocarse en características relevantes\n",
    "- Ensemble de múltiples modelos\n",
    "\n",
    "**Funcionalidad:**\n",
    "- Detección de objetos múltiples\n",
    "- Segmentación semántica\n",
    "- Clasificación jerárquica (especie → raza)\n",
    "\n",
    "**Despliegue:**\n",
    "- API REST para servicio web\n",
    "- Optimización con TensorFlow Lite para móviles\n",
    "- Cuantización para reducir tamaño del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73383ffc",
   "metadata": {},
   "source": [
    "## 15. Conclusiones\n",
    "\n",
    "Este sistema demuestra una implementación completa y robusta de clasificación de imágenes con CNN:\n",
    "\n",
    "**Fortalezas Técnicas:**\n",
    "- Arquitectura bien estructurada con complejidad incremental\n",
    "- Múltiples técnicas de regularización previenen sobreajuste\n",
    "- Callbacks adaptativos optimizan el proceso de entrenamiento\n",
    "- Pipeline de datos eficiente con augmentación inteligente\n",
    "\n",
    "**Aplicabilidad Práctica:**\n",
    "- Sistema modular fácil de extender\n",
    "- Código bien documentado y mantenible\n",
    "- Balance entre rendimiento y precisión\n",
    "- Visualizaciones para interpretabilidad\n",
    "\n",
    "**Valor Educativo:**\n",
    "- Implementa conceptos fundamentales de deep learning\n",
    "- Demuestra mejores prácticas en arquitectura CNN\n",
    "- Ejemplifica workflow completo desde datos hasta producción\n",
    "\n",
    "El sistema sirve como base sólida para proyectos de clasificación de imágenes y puede adaptarse fácilmente a otros dominios manteniendo la misma estructura arquitectónica."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
